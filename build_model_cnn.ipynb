{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  \n",
    "import numpy as np    \n",
    "from sklearn.model_selection import train_test_split     \n",
    "from tensorflow.keras.preprocessing.text import Tokenizer  \n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences  \n",
    "from tensorflow.keras.models import Sequential     \n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, GlobalMaxPooling1D\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint   \n",
    "from tensorflow.keras.models import load_model   \n",
    "from keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Conv2D"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('IMDB Dataset.csv')\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = df['review']    \n",
    "y_data = df['sentiment']  \n",
    "\n",
    "x_data = x_data.replace({'<.*?>': ''}, regex = True)          \n",
    "x_data = x_data.replace({'[^A-Za-z]': ' '}, regex = True)     \n",
    "x_data = x_data.apply(lambda review: [w.lower() for w in review])  \n",
    "\n",
    "y_data = y_data.replace('positive', 1)\n",
    "y_data = y_data.replace('negative', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Set\n",
      "34194    [i,  , s, a, w,  , t, h, i, s,  , f, i, l, m, ...\n",
      "48493    [d, i, s, t, a, s, t, e, f, u, l,  ,  , c, l, ...\n",
      "48934    [t, h, i, s,  , h, a, s,  , g, o, t,  , t, o, ...\n",
      "44182    [ , c, h, i, p, s,  ,  , i, s,  , a, n,  , e, ...\n",
      "41795    [w, h, a, t,  , i, n,  , g, o, d,  , s,  , n, ...\n",
      "                               ...                        \n",
      "10155    [f, i, r, s, t, l, y,  ,  , i,  , w, o, u, l, ...\n",
      "19368    [i,  , m,  , n, o, t,  , a, l, o, n, e,  , i, ...\n",
      "3733     [i,  , m,  , s, o, r, r, y,  ,  , b, u, t,  , ...\n",
      "12482    [i,  , s, a, w,  , t, h, i, s,  , m, o, v, i, ...\n",
      "3089     [t, h, i, s,  , f, i, l, m,  , s, h, o, w, s, ...\n",
      "Name: review, Length: 40000, dtype: object \n",
      "\n",
      "31497    [a, s,  , a,  , w, r, i, t, i, n, g,  , t, e, ...\n",
      "2364     [o, n, e,  , o, f,  , m, y,  , d, e, s, i, r, ...\n",
      "3878     [f, i, r, s, t,  , w, e, e, k,  , o, f,  , m, ...\n",
      "9059     [f, u, l, l,  , m, a, r, k, s,  , f, o, r,  , ...\n",
      "2340     [i,  , l, o, v, e,  , a, a, r, o, n,  , c, a, ...\n",
      "                               ...                        \n",
      "11791    [a, s, i, a,  , a, r, g, e, n, t, o,  , i, s, ...\n",
      "49176    [w, h, e, r, e,  , d, o,  , i,  , b, e, g, i, ...\n",
      "42323    [i, r, r, i, t, a, t, i, n, g,  ,  , i, l, l, ...\n",
      "36748    [ ,  ,  ,  ,  ,  ,  ,  ,  ,  ,  ,  ,  ,  , p, ...\n",
      "39979    [t, d, y,  , i, s,  , p, r, o, b, a, b, l, y, ...\n",
      "Name: review, Length: 10000, dtype: object \n",
      "\n",
      "Test Set\n",
      "34194    1\n",
      "48493    0\n",
      "48934    0\n",
      "44182    1\n",
      "41795    0\n",
      "        ..\n",
      "10155    1\n",
      "19368    0\n",
      "3733     0\n",
      "12482    0\n",
      "3089     1\n",
      "Name: sentiment, Length: 40000, dtype: int64 \n",
      "\n",
      "31497    0\n",
      "2364     1\n",
      "3878     1\n",
      "9059     0\n",
      "2340     1\n",
      "        ..\n",
      "11791    0\n",
      "49176    0\n",
      "42323    0\n",
      "36748    1\n",
      "39979    0\n",
      "Name: sentiment, Length: 10000, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size = 0.2)\n",
    "\n",
    "print('Train Set')\n",
    "print(x_train, '\\n')\n",
    "print(x_test, '\\n')\n",
    "print('Test Set')\n",
    "print(y_train, '\\n')\n",
    "print(y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1286"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_length = [len(x) for x in x_train]\n",
    "max_length = int(np.ceil(np.mean(review_length)))\n",
    "max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded X Train\n",
      " [[ 5  1  7 ...  0  0  0]\n",
      " [12  5  7 ...  0  0  0]\n",
      " [ 3 10  5 ...  0  0  0]\n",
      " ...\n",
      " [ 5  1 14 ...  0  0  0]\n",
      " [ 5  1  7 ...  0  0  0]\n",
      " [ 3 10  5 ...  0  0  0]] \n",
      "\n",
      "Encoded X Test\n",
      " [[ 4  7  1 ...  0  0  0]\n",
      " [ 6  8  2 ...  0  0  0]\n",
      " [16  5  9 ... 13  5  3]\n",
      " ...\n",
      " [ 5  9  9 ...  0  0  0]\n",
      " [ 1  1  1 ...  0  0  0]\n",
      " [ 3 12 18 ...  0  0  0]] \n",
      "\n",
      "Maximum review length:  1286\n"
     ]
    }
   ],
   "source": [
    "token = Tokenizer(lower=False)\n",
    "token.fit_on_texts(x_train)\n",
    "\n",
    "x_train = token.texts_to_sequences(x_train) # text to dynamic-size array of id\n",
    "x_test = token.texts_to_sequences(x_test)\n",
    "\n",
    "x_train = pad_sequences(x_train, maxlen=max_length, padding='post', truncating='post') # array of id to fixed-size array of id (size = 1286)\n",
    "x_test = pad_sequences(x_test, maxlen=max_length, padding='post', truncating='post')\n",
    "\n",
    "total_words = len(token.word_index) + 1\n",
    "\n",
    "print('Encoded X Train\\n', x_train, '\\n')\n",
    "print('Encoded X Test\\n', x_test, '\\n')\n",
    "print('Maximum review length: ', max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((40000, 1286), 28)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, total_words"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_8 (Embedding)     (None, 1286, 64)          1792      \n",
      "                                                                 \n",
      " conv1d_4 (Conv1D)           (None, 1282, 128)         41088     \n",
      "                                                                 \n",
      " global_max_pooling1d_3 (Glo  (None, 128)              0         \n",
      " balMaxPooling1D)                                                \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 24)                3096      \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 1)                 25        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 46,001\n",
      "Trainable params: 46,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(total_words, output_dim=64, input_length = max_length)) # input: (None, 1286 words,)  -> output(None, 1286 words, 32 bytes each word)\n",
    "model.add(Conv1D(128, 5, activation='relu'))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Dense(24, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# compile model\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "313/313 [==============================] - 20s 64ms/step - loss: 0.2946 - accuracy: 0.8747\n",
      "Epoch 2/5\n",
      "313/313 [==============================] - 18s 59ms/step - loss: 0.2920 - accuracy: 0.8751\n",
      "Epoch 3/5\n",
      "313/313 [==============================] - 19s 60ms/step - loss: 0.2814 - accuracy: 0.8797\n",
      "Epoch 4/5\n",
      "313/313 [==============================] - 19s 60ms/step - loss: 0.2738 - accuracy: 0.8839\n",
      "Epoch 5/5\n",
      "313/313 [==============================] - 19s 61ms/step - loss: 0.2652 - accuracy: 0.8877\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x4080307f0>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, batch_size = 128, epochs = 5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 3s 9ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4524"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = [0 if x < 0.5 else 1 for x in y_pred]\n",
    "accuracy = y_pred.count(1)/len(y_pred)\n",
    "accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
